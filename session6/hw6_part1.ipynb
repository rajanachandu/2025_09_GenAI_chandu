{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a586b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 5.666666666666667 Median: 5.5 Mode: 2\n"
     ]
    }
   ],
   "source": [
    "#1. Write a Python function that takes a list of numbers and returns the mean, median, and mode.\n",
    "from statistics import mean, median, mode\n",
    "\n",
    "def find_mean_median_mode(num_list):\n",
    "        avg=mean(num_list)\n",
    "        med=median(num_list)\n",
    "        mod=mode(num_list)\n",
    "        return avg, med, mod\n",
    "\n",
    "data = [2,4,5,6,8,9]\n",
    "avg_val, med_val, mod_val = find_mean_median_mode(data)\n",
    "print(\"Mean:\", avg_val, \"Median:\", med_val, \"Mode:\", mod_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4940554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900.0\n"
     ]
    }
   ],
   "source": [
    "#2. Create a dictionary to represent employee details (name, department, salary). Write a function to increase salary by 10%.\n",
    "\n",
    "def inc_sal(emp_det):\n",
    "    for key, value in emp_det.items():\n",
    "        if key == 'salary':\n",
    "            #return value\n",
    "            return value+((value*10)/100)\n",
    "\n",
    "\n",
    "emp_details = {'name':'John', 'department':'HR', 'salary':  9000}\n",
    "salary = inc_sal(emp_details)\n",
    "print(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffd846e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#3. Write a function that counts how many words occur more than once in a given paragraph.\n",
    "\n",
    "def count_words(text):\n",
    "    \n",
    "    words = text.lower().split()\n",
    "    word_cnt ={}\n",
    "    \n",
    "    for word in words:\n",
    "        word_cnt[word] = word_cnt.get(word,0)+1\n",
    "\n",
    "    words_more_than_1 = [word for word, count in word_cnt.items() if count>1]\n",
    "\n",
    "    return len(words_more_than_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cnt = count_words(\"This is a test a test to test \")\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dc36ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to student.json\n",
      "Data read from student.json\n",
      "Loaded data: {'name': 'Alice', 'age': 22, 'major': 'Computer Science', 'courses': ['AI', 'Data Structures', 'Machine Learning']}\n"
     ]
    }
   ],
   "source": [
    "#5. Write a script to read and write JSON files using the `json` module.\n",
    "\n",
    "import json\n",
    "\n",
    "# Function to write data to a JSON file\n",
    "def write_json_file(filename, data):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file, indent=4)  # indent=4 makes it look nice and readable\n",
    "    print(f\"Data written to {filename}\")\n",
    "\n",
    "# Function to read data from a JSON file\n",
    "def read_json_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    print(f\"Data read from {filename}\")\n",
    "    return data\n",
    "\n",
    "student_data = {\n",
    "    \"name\": \"Alice\",\n",
    "    \"age\": 22,\n",
    "    \"major\": \"Computer Science\",\n",
    "    \"courses\": [\"AI\", \"Data Structures\", \"Machine Learning\"]\n",
    "}\n",
    "\n",
    "# Write to JSON file\n",
    "write_json_file(\"student.json\", student_data)\n",
    "\n",
    "# Read from JSON file\n",
    "data_loaded = read_json_file(\"student.json\")\n",
    "print(\"Loaded data:\", data_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e16af39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chandurajana/Documents/Chandu_Training/2025_09_GenAI_chandu/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between sentences: 0.5545\n"
     ]
    }
   ],
   "source": [
    "#6. Using `SentenceTransformer`, encode two sentences and compute cosine similarity.\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load a pre-trained SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Two example sentences\n",
    "sentence1 = \"Machine learning is fascinating.\"\n",
    "sentence2 = \"Artificial intelligence is a rapidly growing field.\"\n",
    "\n",
    "# Encode the sentences into embeddings\n",
    "embeddings = model.encode([sentence1, sentence2])\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "\n",
    "print(f\"Cosine similarity between sentences: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58476dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to /Users/chandurajana/Documents/Chandu_Training/2025_09_GenAI_chandu/session6/sentence_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "#7.Write a function that creates embeddings for each sentence in a text file and saves them as a CSV.\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def create_embeddings(input_file,output_file):\n",
    "    # Load a pre-trained SentenceTransformer model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    sentences = []\n",
    "   \n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    sentences.append(line)\n",
    "    except FileNotFoundError:\n",
    "            print(f\"Error: The file '{input_file}' does not exist.\")\n",
    "            return None\n",
    "\n",
    "# Generate embeddings for each sentence\n",
    "    embeddings = model.encode(sentences)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'sentence': sentences,\n",
    "        'embedding': [embedding.tolist() for embedding in embeddings]\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Embeddings saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "create_embeddings('/Users/chandurajana/Documents/Chandu_Training/2025_09_GenAI_chandu/session6/RAG.txt', \n",
    "'/Users/chandurajana/Documents/Chandu_Training/2025_09_GenAI_chandu/session6/sentence_embeddings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
