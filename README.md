# My Python & LLM Learning Journey ðŸš€

This repository documents my hands-on learning experience in **Python programming**, **Large Language Models (LLMs)**, and the **Retrieval-Augmented Generation (RAG)** architecture. It serves as a personal knowledge base and a showcase of my progress in understanding modern AI technologies.

## ðŸ“˜ Overview
Throughout this learning journey, I have explored:
- Core **Python programming concepts** including data structures, functions, file handling, and NumPy operations.
- Practical applications of **Large Language Models (LLMs)** such as **Llama**, **Mistral**, and others using tools like **Ollama**.
- Building and experimenting with **RAG (Retrieval-Augmented Generation)** systems to enhance model performance by integrating external knowledge sources.

## ðŸ§  Key Learnings
- Writing clean, modular, and efficient Python code.  
- Running and interacting with local LLMs using Python and subprocess-based scripts.  
- Understanding the difference between traditional fine-tuning and RAG-based approaches.  
- Using **vector databases** (like Milvus or FAISS) and **embeddings** for intelligent data retrieval.  
- Combining retrieval and generation steps to create more accurate, context-aware AI responses.

## ðŸ§© Technologies Explored
- **Python 3**
- **NumPy**
- **Ollama (Llama2, Mistral models)**
- **RAG pipeline concepts**
- **Vector Databases (Milvus, FAISS)**

## ðŸŽ¯ Goals
- Continue building end-to-end prototypes using LLMs and RAG.
- Document new experiments and insights in this repository.
- Apply these learnings to real-world AI applications.

---

ðŸ’¡ *This repository is an evolving collection of scripts, notes, and examples â€” a reflection of continuous learning in the field of applied AI and Python programming.*
